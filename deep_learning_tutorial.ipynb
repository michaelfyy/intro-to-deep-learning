{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelfyy/intro-to-deep-learning/blob/main/deep_learning_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b9c5bd2",
      "metadata": {
        "id": "7b9c5bd2"
      },
      "source": [
        "# Deep Learning & Computer Vision Workshop\n",
        "\n",
        "### MLP on MNIST using PyTorch\n",
        "\n",
        "Welcome to this interactive tutorial! In this notebook, we will introduce some general concepts in deep learning and computer vision and then build a simple Multi-Layer Perceptron (MLP) to classify handwritten digits from the MNIST dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4536c08",
      "metadata": {
        "id": "c4536c08"
      },
      "source": [
        "## Overview\n",
        "\n",
        "- **Deep Learning:** A branch of machine learning that uses neural networks with many layers to learn complex patterns.\n",
        "- **Computer Vision:** A field of artificial intelligence focused on interpreting visual information from images or videos.\n",
        "- **Multi-Layer Perceptron (MLP):** One of the foundational neural network models that consists of an input layer, one or more hidden layers, and an output layer.\n",
        "\n",
        "In this tutorial, we'll:\n",
        "1. Visualize the MNIST dataset\n",
        "2. Build and train a simple MLP\n",
        "3. Visualize predictions\n",
        "4. Evaluate the overall accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ad7f92a",
      "metadata": {
        "id": "0ad7f92a"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Check if CUDA (GPU) is available; otherwise, use CPU\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b10b4a",
      "metadata": {
        "id": "c3b10b4a"
      },
      "outputs": [],
      "source": [
        "# Define a transform to convert images to PyTorch tensors\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# Download and load the MNIST training and test datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders for batching\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=1000, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0764f47",
      "metadata": {
        "id": "f0764f47"
      },
      "source": [
        "## Visualizing the MNIST Dataset\n",
        "\n",
        "Let's take a look at some examples from the MNIST dataset to see the handwritten digits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3c12e27",
      "metadata": {
        "id": "b3c12e27"
      },
      "outputs": [],
      "source": [
        "# Function to display an image\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    # If the image has one channel, squeeze it; otherwise, transpose to HWC format\n",
        "    if npimg.shape[0] == 1:\n",
        "        npimg = npimg.squeeze(0)\n",
        "        plt.imshow(npimg, cmap='gray')\n",
        "    else:\n",
        "        npimg = np.transpose(npimg, (1, 2, 0))\n",
        "        plt.imshow(npimg)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Get a batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# Display the first 8 images\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "print('GroundTruth:', ' '.join(str(labels[j].item()) for j in range(8)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbca8dc8",
      "metadata": {
        "id": "bbca8dc8"
      },
      "source": [
        "## Building the MLP Model\n",
        "\n",
        "We'll build a simple neural network with one hidden layer. The input layer has 784 neurons (since each MNIST image is 28x28 pixels), and the output layer has 10 neurons (one for each digit)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de1d73d3",
      "metadata": {
        "id": "de1d73d3"
      },
      "outputs": [],
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size=784, hidden_size=128, num_classes=10):\n",
        "        super(MLP, self).__init__()\n",
        "        # First fully connected layer\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        # Activation function\n",
        "        self.relu = nn.ReLU()\n",
        "        # Output layer\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Flatten the image tensor into a vector\n",
        "        x = x.view(x.size(0), -1)\n",
        "        # Forward pass through the first layer and activation\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        # Pass through the output layer\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "# Instantiate the model and move it to the selected device\n",
        "model = MLP().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8b12de8",
      "metadata": {
        "id": "a8b12de8"
      },
      "source": [
        "## Training the Model\n",
        "\n",
        "We now set up our loss function and optimizer and train the MLP on the MNIST training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1ac5e5d",
      "metadata": {
        "id": "e1ac5e5d"
      },
      "outputs": [],
      "source": [
        "# Define the loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Set the number of epochs\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        # Move images and labels to the device (CPU or GPU)\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        # Forward pass: Compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass: Zero gradients, perform backpropagation, and update weights\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if (i+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44a7b3dd",
      "metadata": {
        "id": "44a7b3dd"
      },
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "After training, we evaluate the model on the test dataset and visualize some predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a97f83e3",
      "metadata": {
        "id": "a97f83e3"
      },
      "outputs": [],
      "source": [
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Initialize variables to track accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        # Get the predicted class with the highest score\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Accuracy of the model on the 10000 test images: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a6f4a9a",
      "metadata": {
        "id": "1a6f4a9a"
      },
      "outputs": [],
      "source": [
        "# Visualize predictions for a batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images, labels = images.to(device), labels.to(device)\n",
        "outputs = model(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "# Move images to CPU for visualization\n",
        "images = images.cpu()\n",
        "\n",
        "# Display the first 8 test images along with their predicted labels\n",
        "imshow(torchvision.utils.make_grid(images[:8]))\n",
        "print('Predicted:', ' '.join(str(predicted[j].item()) for j in range(8)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65a8f5e6",
      "metadata": {
        "id": "65a8f5e6"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this tutorial, we've explored the basics of deep learning and computer vision by building an MLP to classify the MNIST dataset. We visualized the dataset, built and trained the model, and evaluated its performance. This is just the beginning—there is a vast world of deep learning techniques waiting to be explored!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}